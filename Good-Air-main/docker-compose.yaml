services:
  # Service Airflow Webserver
  airflow-webserver:
    image: apache/airflow:2.10.4
    container_name: airflow-webserver
    command: webserver
    ports:
      - "8888:8080"
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:Affili%4012707@host.docker.internal:5432/airflow_data
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://postgres:Affili%4012707@host.docker.internal:5432/airflow_data
      AIRFLOW__CORE__FERNET_KEY: "w3HvDV5CchLaYmwXZcMceQV5e-7fGuj3M_OXGbCIKts="
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__API__TEST_CONNECTION: "Enabled"
      # Variables MinIO pour les scripts
      MINIO_URL: "http://minio:9000"
      MINIO_ACCESS_KEY: "minioadmin"
      MINIO_SECRET_KEY: "minioadmin"
    extra_hosts:
      - "host.docker.internal:host-gateway" # Permet aux conteneurs d'accéder à l'hôte
    volumes:
      - ./data:/opt/airflow/data
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs # Ajout du dossier contenant les DAGs
      - D:/Course/EPSI M1 IA/Cours/Data pipeline/MinIO:/opt/airflow/pipeline
    restart: always
    depends_on:
      - airflow-init
      - redis
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8888/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # Service Redis pour Celery
  redis:
    image: redis:7.2-bookworm
    container_name: redis
    expose:
      - 6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always

  # Service Airflow Scheduler
  airflow-scheduler:
    image: apache/airflow:2.10.4
    container_name: airflow-scheduler
    command: scheduler
    environment:
      AIRFLOW__CORE__FERNET_KEY: "w3HvDV5CchLaYmwXZcMceQV5e-7fGuj3M_OXGbCIKts="
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:Affili%4012707@host.docker.internal:5432/airflow_data
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://postgres:Affili%4012707@host.docker.internal:5432/airflow_data
      # Variables MinIO pour les scripts
      MINIO_URL: "http://minio:9000"
      MINIO_ACCESS_KEY: "minioadmin"
      MINIO_SECRET_KEY: "minioadmin"
    volumes:
      - ./data:/opt/airflow/data
      - ./dags:/opt/airflow/dags # Ajout du dossier contenant les DAGs
      - ./logs:/opt/airflow/logs
      - D:/Course/EPSI M1 IA/Cours/Data pipeline/MinIO:/opt/airflow/pipeline
    depends_on:
      - airflow-webserver
      - redis
    restart: always

  # Service Airflow Worker
  airflow-worker:
    image: apache/airflow:2.10.4
    container_name: airflow-worker
    command: worker
    environment:
      AIRFLOW__CORE__FERNET_KEY: "w3HvDV5CchLaYmwXZcMceQV5e-7fGuj3M_OXGbCIKts="
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:Affili%4012707@host.docker.internal:5432/airflow_data
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://postgres:Affili%4012707@host.docker.internal:5432/airflow_data
      # Variables MinIO pour les scripts
      MINIO_URL: "http://minio:9000"
      MINIO_ACCESS_KEY: "minioadmin"
      MINIO_SECRET_KEY: "minioadmin"
    volumes:
      - ./data:/opt/airflow/data
      - ./dags:/opt/airflow/dags # Ajout du dossier contenant les DAGs]
      - ./logs:/opt/airflow/logs
      - D:/Course/EPSI M1 IA/Cours/Data pipeline/MinIO:/opt/airflow/pipeline
    depends_on:
      - airflow-webserver
      - airflow-scheduler
      - redis
    restart: always

  # Service pour initialiser la base de données Airflow
  airflow-init:
    image: apache/airflow:2.10.4
    container_name: airflow-init
    command: bash -c "airflow db upgrade && airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@admin.com --password admin"
    environment:
      AIRFLOW__CORE__FERNET_KEY: "w3HvDV5CchLaYmwXZcMceQV5e-7fGuj3M_OXGbCIKts="
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:Affili%4012707@host.docker.internal:5432/airflow_data
    restart: "no"
    
  # Service MinIO pour le stockage objet
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9002:9000"      # API
      - "9001:9001"      # Console
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - ./minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
